



# 1、数据并行（Data Parallel）

![image-20240103212544569](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103212544569.png)

​	参数服务器显卡，0号显卡，  三张训练显卡，1 号，2号，3号显卡。



过程：

1. 参数服务器进行下发参数。

2. 数据在三张显卡上进行训练，前向传播和反向传播就能够得到梯度。然后将三张显卡上的梯度进行 聚合（取平均等)，然后将梯度传回我们的参数服务器。
3. 此时参数服务器上有完整的模型参数和梯度，那么我们就可以使用优化器对我们参数进行更新。





**多张显卡的合作模式：**

## 1.1 广播 Broadcast

![image-20240103213935634](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103213935634.png)

广播算子要做的事情就是把数据，从其中的一张显卡上传播到其它的显卡上。



## 1.2 Reduce（规约）

第二个多张显卡的通信算子是 规约



![image-20240103214201284](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103214201284.png)

规约，可以是求和、取max、min，取平均。

​	其实就是将多张显卡的数据进行规约后，放到其中一张显卡上。



## 1.3  All Reduce

![image-20240103214831050](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103214831050.png)

​	All reduce ，是在规约的基础上，我们把结果告诉所有的显卡。



## 1.4 Reduce Scatter

**![image-20240103215036543](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103215036543.png)**

​		把规约的结果，发给所有的显卡， 但是不同之处在于，每张显卡只得到一部分的规约结果。

![image-20240103215301780](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103215301780.png)

​		例如：规约是相加

​	0号显卡得到的是in0 的前1/4参数+in1的前1/4+in2的前1/4,+in3的前1/4。

​	1号显卡得到的是in0 的前2/4参数+in1的前2/4+in2的前2/4,+in3的前2/4。

​	0号显卡得到的是in0 的前3/4参数+in1的前3/4+in2的前3/4,+in3的前3/4。

​	0号显卡得到的是in0 的前4/4参数+in1的前4/4+in2的前4/4,+in3的前4/4。



## 1.5 All Gather (收集)



![image-20240103215908859](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103215908859.png)



收集的意思是，我们把每张显卡上的结果 进行一个拼接。然后再广播到所有的显卡上。





## 1.5 分布式数据并行

![image-20240103220720846](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103220720846.png)

​			分布式规约，舍弃了参数服务器，每个服务器进行前向传播和反向传播之后得到梯度，然后将梯度进行规约后，传播给所有的显卡，然后再使用 优化器进行更新参数即可。 最后1,2,3 显卡上得到的参数就是一样的参数。





## 1.6 数据并行带来的显存上的优化

![image-20240103221710681](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103221710681.png)

​	**本质上是将batchsize给降低了。那么 产生的中间结果就减少了。**

**数据并行的缺点：**

​	如果某张显卡只分到了很少的数据，极端情况下只有1个数据，此时那张显卡上 几乎无法进行计算。本质上就是数据可能分配不均衡的问题。



# 2、模型并行（Model Parallel）

​	既然我们一张显卡上无法放下所有参数、所有梯度、所有优化器。那么我们就想办法将模型分成很多个小的部分。



![image-20240103222434122](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103222434122.png)

 就是将矩阵向量切成很多份。 根据矩阵乘法性质进行乘法。再将最终结果进行拼接，然后就成了我们最终的模型结果。

![image-20240103230240509](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103230240509.png)

​		**此时我们需要保证每张显卡上，数据的输入是一样的。**

![image-20240103230408877](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103230408877.png)

​		得到拼接结果，就是我们的all Gather这种显卡通信方式。

![image-20240103230441343](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103230441343.png)

​	结果每张显卡的结果就是一部分，然后再进行拼接。



**优点：**

​	每张显卡参数、梯度都变成1/n，而优化器都只用保存相应的部分即可。



**缺点：**

​	缺点是，每张显卡数据都是一样的，所以中间结果并没有减少。 此时当我们的batchsize过大的时候，还是有显存溢出的风险。



# 3、ZeRO（Zero Redundancy Optimizer）

 ![image-20240103231057013](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103231057013.png)

​	Zero Redundancy Optimizer 是基于数据并行的一种优化方式。

​	数据并行的训练方式有个弊端，它们用的是同样的一批梯度和参数去进行参数的更新，实际上每张显卡进行参数更新的时候用的都是同样的一批参数和梯度，它们各自去进行参数优化，会带来计算上的重复和冗余。

为了消除这种冗余，我们每张显卡上，我们只获取一部分的梯度，然后只更新一部分的参数，最后它们进行一个交流，就能够把模型的完整梯度给恢复出来。  



步骤：

第一阶段：

![image-20240103231657750](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103231657750.png)





第二阶段：

![image-20240103232022217](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103232022217.png)

​	第二阶段，梯度分配的时候（Average gradients using Reduce Scatter），此时是在反向传播的时候用梯度Gradient* 去代替原来保存的中间结果的梯度Gradient。

 这相比第一阶段还需要将中间梯度保存下来，更能节约显存。



![image-20240103232446069](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103232446069.png)

这个阶段，每张显卡上只有一部分的参数，梯度。但是只有一部分的数据，此时怎么实现前向传播和反向传播呢。（既不是模型并行，也不是数据并行）。



在进行前向传播的时候，会临时将每张显卡上的参数进行临时拼接： all gather，每当我们用完的时候，我们会把这个参数给从显卡中释放，恢复成每张显卡只保留一部分的那种形式。需要注意的时候，在进行模型的反向传播的时候，也需要完整模型参数，也需要gather一下。

相比于ZeRO2,是一个时间换空间的做法。（因为gather了两次）



显存分析：

![image-20240103233629331](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103233629331.png)

​			

# 4、Pipeline Parallel

流水线的并行方法

![image-20240103233806733](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103233806733.png)

​		其实就是将每一层（某几层）进行划分到显卡上，比如说第0层到卡0，第一次到卡1，第二层到卡2。如此，前向传播，第一层结果有了之后再给第二层，第二层结果有了之后再给第三层。如此类推。反向传播则是从后往前

​		优点：

​		数据的原始输入不是数据并行。

​				单张显卡参数量、梯度量、优化器，中间结果也变少。 

缺点：

​	显卡0在工作时，显卡1、2闲置，造成资源的浪费。

​	后续还是有 对Pipe Line方式的优化的。



# 5 混合精度训练

本质上，精度越高，表示范围越大，精度也越大。但是运算时间越长。



![image-20240103234508909](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103234508909.png)

一般默认是FP32的精度进行训练，但是FP16的计算会比FP32更快； 实际上在训练的过程中，模型的参数一般是不会超过千（有时候归一化之后，还可能只是0-1，或者-1~1之间），那么完全在fp16的数值表示范围之内。 我们能不能通过这样的一个从FP32 ，转成fp16，去带来我们运算速度上的提升。

**挑战：**

​		参数更新约等于 梯度乘以学习率，而学习率 的表示范围有时候更小，比如e^-4, e^-5数量级，再乘以一个梯度，此时可能就变成了0了(下溢)。

**solution：**

​	我们将fp16表示的梯度 乘以学习率表示为fp32，我们用更高的精度表示参数的更新。

所以我们在优化器上需要额外保存一个单精度（fp32）的参数

![image-20240103235343527](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103235343527.png)

​		即优化器的更新量，我们需要保存为单精度（fp32）类型.  然后再转回fp16类型（半精度类型），供模型进行计算。



# 7、Offloading



![image-20240103235732997](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240103235732997.png)

​	这种优化技术就是将， 优化器从显卡中剥离。 放到cpu中，而让gpu绑定多张cpu，可以让每张cpu计算量降到足够的低，此时cpu的运算就不会成为模型训练的瓶颈，此时，梯度也从gpu放到cpu然后进行参数更新，然后将更新后的参数回传给gpu。



# 8、Overlapping

第三个技巧是通信计算的重叠。



![image-20240104000414628](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240104000414628.png)

在cpu中，它的memory的操作一般是异步的。

​		其实就是，如果使用gather形式，或者pipeline形式，我们可以使用异步去先获取下一层的参数，然后直接调用异步获取结果即可。



# 8、checkpointing

![image-20240104001029303](C:\Users\RichardPan0000\AppData\Roaming\Typora\typora-user-images\image-20240104001029303.png)